import os
import argparse
import fitz
import base64
import requests
import time
import mimetypes
from PIL import Image
from dotenv import load_dotenv
import glob
import math

# --- é…ç½® ---
# ä».envæ–‡ä»¶åŠ è½½APIå¯†é’¥
load_dotenv(dotenv_path="./API.env")
API_KEY = os.getenv("GOOGLE_API_KEY")

MODEL_NAME = "gemini-2.5-flash"
# MODEL_NAME = "gemini-2.5-flash-lite-preview-06-17"
# MODEL_NAME = "gemini-2.0-flash"
# MODEL_NAME = "gemini-2.0-flash-lite"
API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME}:generateContent"

def get_image_mime_type(file_path):
    """è·å–å›¾åƒæ–‡ä»¶çš„MIMEç±»å‹ã€‚"""
    mime_type, _ = mimetypes.guess_type(file_path)
    if mime_type and mime_type.startswith('image/'):
        try:
            with Image.open(file_path) as img:
                format_to_mime = {
                    'JPEG': 'image/jpeg',
                    'PNG': 'image/png',
                    'GIF': 'image/gif',
                    'WEBP': 'image/webp',
                    'BMP': 'image/bmp'
                }
                pillow_mime = format_to_mime.get(img.format)
                if pillow_mime:
                    return pillow_mime
                else:
                    return mime_type if mime_type else None
        except Exception:
            return mime_type if mime_type else None
    return None

def encode_image(image_path):
    """å°†å›¾åƒæ–‡ä»¶ç¼–ç ä¸ºbase64ã€‚"""
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šæœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶ {image_path}")
        return None
    except Exception as e:
        print(f"è¯»å–æˆ–ç¼–ç å›¾åƒæ—¶å‡ºé”™: {e}")
        return None

def extract_text_from_images_batch(image_paths, start_page_num=1, max_retries=3, api_delay=10):
    """
    æ‰¹é‡å°†å¤šå¼ å›¾åƒå‘é€åˆ°Gemini APIå¹¶è¯·æ±‚æå–æ–‡æœ¬å¹¶æ ¼å¼åŒ–ä¸ºLaTeXã€‚
    æ”¯æŒé‡è¯•æœºåˆ¶ã€‚
    
    Args:
        image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
        start_page_num: èµ·å§‹é¡µç ï¼Œç”¨äºç”Ÿæˆæ­£ç¡®çš„é¡µé¢æ ‡é¢˜
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤ä¸º3æ¬¡
        api_delay: APIè°ƒç”¨é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé‡è¯•æ—¶ä¹Ÿä¼šä½¿ç”¨æ­¤å»¶è¿Ÿ
    
    Returns:
        æˆåŠŸæ—¶è¿”å›æå–çš„æ–‡æœ¬å†…å®¹åˆ—è¡¨ï¼Œå¤±è´¥æ—¶è¿”å›None
    """
    if not API_KEY:
        print("é”™è¯¯ï¼šåœ¨ç¯å¢ƒå˜é‡æˆ–.envæ–‡ä»¶ä¸­æœªæ‰¾åˆ°GOOGLE_API_KEYã€‚")
        return None

    if not image_paths:
        print("é”™è¯¯ï¼šæ²¡æœ‰æä¾›å›¾åƒè·¯å¾„ã€‚")
        return None

    print(f"æ‰¹é‡å¤„ç† {len(image_paths)} å¼ å›¾ç‰‡ (é¡µé¢ {start_page_num}-{start_page_num + len(image_paths) - 1})...")

    # å‡†å¤‡APIè¯·æ±‚çš„parts
    parts = []
    
    # æ„å»ºè¯¦ç»†çš„æç¤ºæ–‡æœ¬
    if len(image_paths) == 1:
        prompt_text = f"Extract all the visible text from this image (page {start_page_num}) and output the result as ordinary markdown text. For formulas, output them in LaTeX format using $ for inline math and $ for block math."
    else:
        page_numbers = [str(start_page_num + i) for i in range(len(image_paths))]
        end_page_num = start_page_num + len(image_paths) - 1
        prompt_text = f"""Extract all the visible text from these {len(image_paths)} consecutive document pages (pages {', '.join(page_numbers)}) and output the result as ordinary markdown text. 

For each page, please:
1. Start with a header like "## Page X" where X is the actual page number
2. Extract all visible text content
3. Format formulas in LaTeX using $ for inline math and $ for block math
4. Maintain the original document structure and formatting
5. Separate each page with a clear delimiter

Process the pages in order from page {start_page_num} to page {end_page_num}."""

    parts.append({"text": prompt_text})

    # ä¸ºæ¯å¼ å›¾ç‰‡æ·»åŠ inline_dataéƒ¨åˆ†
    encoded_images = []
    for i, image_path in enumerate(image_paths):
        mime_type = get_image_mime_type(image_path)
        if not mime_type:
            print(f"é”™è¯¯ï¼šæ— æ³•ç¡®å®š{image_path}çš„æ”¯æŒå›¾åƒMIMEç±»å‹ã€‚")
            print("æ”¯æŒçš„ç±»å‹ï¼šJPEG, PNG, GIF, WEBP, BMP")
            continue

        encoded_image = encode_image(image_path)
        if not encoded_image:
            print(f"è­¦å‘Šï¼šè·³è¿‡æ— æ³•ç¼–ç çš„å›¾åƒ {image_path}")
            continue

        parts.append({
            "inline_data": {
                "mime_type": mime_type,
                "data": encoded_image
            }
        })
        encoded_images.append((image_path, mime_type))
        print(f"  å·²ç¼–ç å›¾ç‰‡ {i+1}/{len(image_paths)}: {os.path.basename(image_path)} ({mime_type})")

    if not encoded_images:
        print("é”™è¯¯ï¼šæ²¡æœ‰æˆåŠŸç¼–ç ä»»ä½•å›¾åƒã€‚")
        return None

    payload = {
        "contents": [
            {
                "parts": parts
            }
        ],
        "generationConfig": {
            "temperature": 0.1,
            "maxOutputTokens": 8192  # å¢åŠ è¾“å‡ºtokené™åˆ¶ä»¥å¤„ç†å¤šé¡µå†…å®¹
        }
    }

    headers = {
        'Content-Type': 'application/json'
    }

    params = {
        'key': API_KEY
    }

    # é‡è¯•æœºåˆ¶
    for attempt in range(max_retries + 1):  # +1 å› ä¸ºåŒ…å«åˆå§‹å°è¯•
        try:
            if attempt > 0:
                print(f"ğŸ”„ é‡è¯•ç¬¬ {attempt} æ¬¡ (å…± {max_retries} æ¬¡é‡è¯•æœºä¼š)...")
                if api_delay > 0:
                    print(f"â³ é‡è¯•å‰ç­‰å¾… {api_delay} ç§’...")
                    time.sleep(api_delay)
            else:
                print(f"æ­£åœ¨å‘é€APIè¯·æ±‚ (åŒ…å« {len(encoded_images)} å¼ å›¾ç‰‡)...")
            
            response = requests.post(API_URL, headers=headers, json=payload, params=params, timeout=60)
            response.raise_for_status()

            result = response.json()

            if 'candidates' in result and result['candidates']:
                candidate = result['candidates'][0]
                if 'content' in candidate and 'parts' in candidate['content'] and candidate['content']['parts']:
                    if 'text' in candidate['content']['parts'][0]:
                        extracted_text = candidate['content']['parts'][0]['text']
                        if attempt > 0:
                            print(f"âœ… é‡è¯•æˆåŠŸï¼åœ¨ç¬¬ {attempt} æ¬¡é‡è¯•åæˆåŠŸæå– {len(encoded_images)} å¼ å›¾ç‰‡çš„å†…å®¹")
                        else:
                            print(f"âœ… æˆåŠŸæå– {len(encoded_images)} å¼ å›¾ç‰‡çš„å†…å®¹")
                        return extracted_text.strip()
                    else:
                        error_msg = "APIå“åº”éƒ¨åˆ†ä¸åŒ…å«æ–‡æœ¬"
                        if attempt < max_retries:
                            print(f"âŒ é”™è¯¯ï¼š{error_msg}ï¼Œå‡†å¤‡é‡è¯•...")
                            continue
                        else:
                            print(f"âŒ é”™è¯¯ï¼š{error_msg}ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                            return None
                else:
                    error_msg = "æ„å¤–çš„APIå“åº”ç»“æ„ï¼ˆç¼ºå°‘contentæˆ–partsï¼‰"
                    if attempt < max_retries:
                        print(f"âŒ é”™è¯¯ï¼š{error_msg}ï¼Œå‡†å¤‡é‡è¯•...")
                        continue
                    else:
                        print(f"âŒ é”™è¯¯ï¼š{error_msg}ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                        return None
            elif 'error' in result:
                error_msg = f"APIé”™è¯¯ï¼š{result['error'].get('message', 'æœªçŸ¥é”™è¯¯')}"
                if 'code' in result['error']:
                    error_msg += f"ï¼Œé”™è¯¯ä»£ç ï¼š{result['error']['code']}"
                
                if attempt < max_retries:
                    print(f"âŒ {error_msg}ï¼Œå‡†å¤‡é‡è¯•...")
                    continue
                else:
                    print(f"âŒ {error_msg}ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                    return None
            else:
                error_msg = "æ„å¤–çš„APIå“åº”ç»“æ„ï¼ˆç¼ºå°‘candidatesï¼‰"
                if attempt < max_retries:
                    print(f"âŒ é”™è¯¯ï¼š{error_msg}ï¼Œå‡†å¤‡é‡è¯•...")
                    continue
                else:
                    print(f"âŒ é”™è¯¯ï¼š{error_msg}ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                    return None

        except requests.exceptions.RequestException as e:
            error_msg = f"å‘å‡ºAPIè¯·æ±‚æ—¶å‡ºé”™: {e}"
            if hasattr(e, 'response') and e.response is not None:
                try:
                    error_msg += f"ï¼Œå“åº”çŠ¶æ€ç : {e.response.status_code}"
                    error_msg += f"ï¼Œå“åº”æ–‡æœ¬: {e.response.text[:200]}..."  # é™åˆ¶é”™è¯¯ä¿¡æ¯é•¿åº¦
                except Exception as inner_e:
                    error_msg += f"ï¼Œæ— æ³•è·å–é”™è¯¯å“åº”è¯¦æƒ…: {inner_e}"
            
            if attempt < max_retries:
                print(f"âŒ {error_msg}ï¼Œå‡†å¤‡é‡è¯•...")
                continue
            else:
                print(f"âŒ {error_msg}ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                return None
                
        except Exception as e:
            error_msg = f"å‘ç”Ÿæ„å¤–é”™è¯¯: {e}"
            if attempt < max_retries:
                print(f"âŒ {error_msg}ï¼Œå‡†å¤‡é‡è¯•...")
                continue
            else:
                print(f"âŒ {error_msg}ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                return None

    # è¿™é‡Œä¸åº”è¯¥åˆ°è¾¾ï¼Œä½†ä¸ºäº†å®Œæ•´æ€§
    print("âŒ æ‰€æœ‰é‡è¯•å‡å¤±è´¥")
    return None

def extract_text_from_image(image_path):
    """
    å•å¼ å›¾åƒå¤„ç†çš„å…¼å®¹æ€§å‡½æ•°ï¼Œå†…éƒ¨è°ƒç”¨æ‰¹é‡å¤„ç†å‡½æ•°ã€‚
    ä¿æŒå‘åå…¼å®¹æ€§ã€‚
    """
    result = extract_text_from_images_batch([image_path], 1)
    return result

def convert_pdf_to_images(pdf_path, output_folder=None, dpi=200):
    """
    ä½¿ç”¨PyMuPDF(fitz)å°†PDFè½¬æ¢ä¸ºå›¾ç‰‡å¹¶ä¿å­˜åˆ°æŒ‡å®šæ–‡ä»¶å¤¹
    """
    pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]
    
    if output_folder is None:
        output_folder = pdf_name
    
    os.makedirs(output_folder, exist_ok=True)
    
    print(f"æ­£åœ¨å°†PDF '{pdf_path}' è½¬æ¢ä¸ºå›¾ç‰‡...")
    
    pdf_document = fitz.open(pdf_path)
    
    image_paths = []
    zoom = dpi / 72
    
    for page_num in range(len(pdf_document)):
        print(f"å¤„ç†ç¬¬ {page_num+1}/{len(pdf_document)} é¡µ...")
        
        page = pdf_document.load_page(page_num)
        
        matrix = fitz.Matrix(zoom, zoom)
        pix = page.get_pixmap(matrix=matrix)
        
        image_path = os.path.join(output_folder, f"page_{page_num+1}.png")
        pix.save(image_path)
        image_paths.append(image_path)
        
        print(f"ä¿å­˜ç¬¬ {page_num+1} é¡µåˆ° {image_path}")
    
    pdf_document.close()
    print(f"PDFå·²æˆåŠŸè½¬æ¢ä¸ºå›¾ç‰‡å¹¶ä¿å­˜åˆ° '{output_folder}' æ–‡ä»¶å¤¹")
    return image_paths, output_folder

def process_pdf_file(pdf_path, output_folder=None, dpi=200, batch_size=1, api_delay=10, max_retries=3):
    """
    å¤„ç†å•ä¸ªPDFæ–‡ä»¶ï¼Œè½¬æ¢ä¸ºLaTeXå¹¶ä¿å­˜ä¸ºä¸PDFåŒåçš„MDæ–‡ä»¶
    
    Args:
        pdf_path: PDFæ–‡ä»¶è·¯å¾„
        output_folder: è¾“å‡ºæ–‡ä»¶å¤¹
        dpi: å›¾åƒåˆ†è¾¨ç‡
        batch_size: æ¯æ¬¡APIè°ƒç”¨å¤„ç†çš„å›¾ç‰‡æ•°é‡
        api_delay: APIè°ƒç”¨é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    """
    image_paths, folder = convert_pdf_to_images(pdf_path, output_folder, dpi)
    
    # è®¡ç®—æ‰¹æ¬¡æ•°é‡
    total_batches = math.ceil(len(image_paths) / batch_size)
    print(f"\nğŸ“‹ å¤„ç†è®¡åˆ’ï¼š{len(image_paths)} å¼ å›¾ç‰‡ï¼Œåˆ† {total_batches} ä¸ªæ‰¹æ¬¡å¤„ç†ï¼ˆæ¯æ‰¹ {batch_size} å¼ ï¼Œæœ€å¤šé‡è¯• {max_retries} æ¬¡ï¼‰")
    
    all_contents = []
    
    for batch_idx in range(total_batches):
        start_idx = batch_idx * batch_size
        end_idx = min(start_idx + batch_size, len(image_paths))
        batch_image_paths = image_paths[start_idx:end_idx]
        start_page_num = start_idx + 1
        
        print(f"\nğŸ”„ å¤„ç†æ‰¹æ¬¡ {batch_idx + 1}/{total_batches} (é¡µé¢ {start_page_num}-{start_page_num + len(batch_image_paths) - 1})...")
        
        # APIè°ƒç”¨é—´éš”æ§åˆ¶
        if batch_idx > 0 and api_delay > 0:
            print(f"â³ ç­‰å¾… {api_delay} ç§’...")
            time.sleep(api_delay)
        
        # æ‰¹é‡å¤„ç†å›¾ç‰‡ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        batch_content = extract_text_from_images_batch(batch_image_paths, start_page_num, max_retries, api_delay)
        
        if batch_content:
            all_contents.append(batch_content)
            
            # ä¿å­˜æ‰¹æ¬¡ä¸´æ—¶æ–‡ä»¶
            batch_temp_file = os.path.join(folder, f"batch_{batch_idx + 1}_pages_{start_page_num}-{start_page_num + len(batch_image_paths) - 1}.md")
            with open(batch_temp_file, "w", encoding="utf-8") as f:
                f.write(batch_content)
            print(f"âœ… å·²ä¿å­˜æ‰¹æ¬¡å†…å®¹åˆ°ä¸´æ—¶æ–‡ä»¶: {batch_temp_file}")
        else:
            print(f"âŒ æ‰¹æ¬¡ {batch_idx + 1} å¤„ç†å¤±è´¥ï¼ˆå·²å°è¯• {max_retries + 1} æ¬¡ï¼‰")
            all_contents.append(f"## æ‰¹æ¬¡ {batch_idx + 1} (é¡µé¢ {start_page_num}-{start_page_num + len(batch_image_paths) - 1})\n\næ— æ³•æå–å†…å®¹ï¼ˆAPIè°ƒç”¨å¤±è´¥ï¼‰")
    
    # åˆå¹¶æ‰€æœ‰å†…å®¹
    if all_contents:
        pdf_basename = os.path.splitext(os.path.basename(pdf_path))[0]
        md_file = os.path.splitext(pdf_path)[0] + ".md"
        
        with open(md_file, "w", encoding="utf-8") as outfile:
            outfile.write(f"# {pdf_basename}\n\n")
            outfile.write(f"*æœ¬æ–‡æ¡£ç”±PDFè‡ªåŠ¨è½¬æ¢ç”Ÿæˆï¼Œå…± {len(image_paths)} é¡µï¼Œä½¿ç”¨æ‰¹é‡å¤„ç†æ¨¡å¼ï¼ˆæ¯æ‰¹ {batch_size} é¡µï¼Œæœ€å¤šé‡è¯• {max_retries} æ¬¡ï¼‰*\n\n")
            
            for i, content in enumerate(all_contents):
                outfile.write(content)
                if i < len(all_contents) - 1:  # ä¸åœ¨æœ€åä¸€ä¸ªå†…å®¹åæ·»åŠ åˆ†éš”ç¬¦
                    outfile.write("\n\n---\n\n")
        
        print(f"ğŸ“„ å·²åˆå¹¶æ‰€æœ‰å†…å®¹å¹¶ä¿å­˜åˆ°: {md_file}")
        
        # ä¿å­˜å‰¯æœ¬åˆ°å›¾ç‰‡æ–‡ä»¶å¤¹
        folder_md_file = os.path.join(folder, pdf_basename + ".md")
        if md_file != folder_md_file:
            with open(folder_md_file, "w", encoding="utf-8") as f:
                f.write(open(md_file, "r", encoding="utf-8").read())
            print(f"ğŸ“„ å·²ä¿å­˜å‰¯æœ¬åˆ°: {folder_md_file}")
        
        return md_file
    else:
        print("âŒ æ²¡æœ‰æˆåŠŸæå–ä»»ä½•å†…å®¹ï¼Œæ— æ³•ç”Ÿæˆæ–‡ä»¶")
        return None

def process_multiple_pdfs(pdf_paths, output_base_folder="output", dpi=200, batch_size=1, api_delay=10, max_retries=3):
    """
    å¤„ç†å¤šä¸ªPDFæ–‡ä»¶
    
    Args:
        pdf_paths: PDFæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        output_base_folder: è¾“å‡ºåŸºç¡€æ–‡ä»¶å¤¹
        dpi: å›¾åƒåˆ†è¾¨ç‡
        batch_size: æ¯æ¬¡APIè°ƒç”¨å¤„ç†çš„å›¾ç‰‡æ•°é‡
        api_delay: APIè°ƒç”¨é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    """
    results = []
    
    os.makedirs(output_base_folder, exist_ok=True)
    
    print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†æ¨¡å¼ï¼šæ¯æ¬¡å¤„ç† {batch_size} å¼ å›¾ç‰‡ï¼Œè°ƒç”¨é—´éš” {api_delay} ç§’ï¼Œæœ€å¤šé‡è¯• {max_retries} æ¬¡")
    
    for i, pdf_path in enumerate(pdf_paths):
        print(f"\nğŸ“š å¤„ç†PDF {i+1}/{len(pdf_paths)}: {pdf_path}")
        
        pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]
        output_folder = os.path.join(output_base_folder, pdf_name)
        
        result = process_pdf_file(pdf_path, output_folder, dpi, batch_size, api_delay, max_retries)
        
        if result:
            results.append((pdf_path, result))
            print(f"âœ… æˆåŠŸå¤„ç† {pdf_path} -> {result}")
        else:
            print(f"âŒ å¤„ç† {pdf_path} å¤±è´¥")
    
    print("\nğŸ“Š å¤„ç†ç»“æœæ‘˜è¦:")
    for pdf_path, md_path in results:
        print(f"âœ… PDF: {pdf_path} -> MD: {md_path}")
    
    if len(results) != len(pdf_paths):
        failed_count = len(pdf_paths) - len(results)
        print(f"âš ï¸  è­¦å‘Šï¼š{failed_count} ä¸ªPDFæ–‡ä»¶å¤„ç†å¤±è´¥")
    
    return results

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="å°†PDFè½¬æ¢ä¸ºMarkdown (åŒ…å«LaTeXæ ¼å¼çš„å…¬å¼) - æ”¯æŒæ‰¹é‡å›¾ç‰‡å¤„ç†å’Œé‡è¯•æœºåˆ¶ã€‚")
    parser.add_argument("--pdf_dir", help="PDFæ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆå°†å¤„ç†è¯¥ç›®å½•ä¸­çš„æ‰€æœ‰PDFï¼‰")
    parser.add_argument("--pdf_files", nargs="+", help="è¦å¤„ç†çš„PDFæ–‡ä»¶åˆ—è¡¨")
    parser.add_argument("--output", default="output", help="è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„")
    parser.add_argument("--dpi", type=int, default=200, help="å›¾åƒåˆ†è¾¨ç‡DPIï¼Œé»˜è®¤ä¸º200")
    parser.add_argument("--batch_size", type=int, default=10, help="æ¯æ¬¡APIè°ƒç”¨å¤„ç†çš„å›¾ç‰‡æ•°é‡")
    parser.add_argument("--api_delay", type=int, default=10, help="APIè°ƒç”¨é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰")
    parser.add_argument("--max_retries", type=int, default=5, help="APIè°ƒç”¨å¤±è´¥æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    args = parser.parse_args()
    
    # å‚æ•°éªŒè¯
    if args.batch_size < 1:
        print("é”™è¯¯ï¼šbatch_sizeå¿…é¡»å¤§äºç­‰äº1")
        exit(1)
    
    if args.api_delay < 0:
        print("é”™è¯¯ï¼šapi_delayä¸èƒ½ä¸ºè´Ÿæ•°")
        exit(1)
    
    if args.max_retries < 0:
        print("é”™è¯¯ï¼šmax_retriesä¸èƒ½ä¸ºè´Ÿæ•°")
        exit(1)

    pdf_paths = []
    
    if args.pdf_dir:
        if not os.path.exists(args.pdf_dir):
            print(f"é”™è¯¯: ç›®å½• '{args.pdf_dir}' ä¸å­˜åœ¨")
            exit(1)
        
        pdf_paths = glob.glob(os.path.join(args.pdf_dir, "*.pdf"))
        if not pdf_paths:
            print(f"è­¦å‘Š: åœ¨ç›®å½• '{args.pdf_dir}' ä¸­æœªæ‰¾åˆ°PDFæ–‡ä»¶")
            exit(0)
    
    elif args.pdf_files:
        for pdf_file in args.pdf_files:
            if os.path.exists(pdf_file):
                pdf_paths.append(pdf_file)
            else:
                print(f"è­¦å‘Š: PDFæ–‡ä»¶ '{pdf_file}' ä¸å­˜åœ¨ï¼Œå°†è¢«è·³è¿‡")
    
    else:
        parser.print_help()
        print("\né”™è¯¯: å¿…é¡»æŒ‡å®š --pdf_dir æˆ– --pdf_files")
        exit(1)
    
    if not pdf_paths:
        print("é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„PDFæ–‡ä»¶")
        exit(1)
    
    print(f"ğŸ¯ é…ç½®ä¿¡æ¯:")
    print(f"  - æ‰¹é‡å¤§å°: {args.batch_size} å¼ å›¾ç‰‡/æ¬¡")
    print(f"  - APIå»¶è¿Ÿ: {args.api_delay} ç§’")
    print(f"  - æœ€å¤§é‡è¯•: {args.max_retries} æ¬¡")
    print(f"  - å›¾åƒDPI: {args.dpi}")
    print(f"  - è¾“å‡ºç›®å½•: {args.output}")
    
    print(f"\nğŸ“ å°†å¤„ç† {len(pdf_paths)} ä¸ªPDFæ–‡ä»¶:")
    for pdf_path in pdf_paths:
        print(f"  - {pdf_path}")
    
    process_multiple_pdfs(pdf_paths, args.output, args.dpi, args.batch_size, args.api_delay, args.max_retries)
    print("\nğŸ‰ æ‰€æœ‰å¤„ç†å®Œæˆï¼")
